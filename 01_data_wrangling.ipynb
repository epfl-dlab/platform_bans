{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os.path\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Local Modules\n",
    "sys.path.insert(0, os.path.abspath('/data/manoel/platform_bans/'))\n",
    "from helpers.regression_helpers import get_slice_date_venue, set_intervention_stuff\n",
    "from helpers.regression_helpers import get_content_helper\n",
    "from helpers.vars import interventions, grace_period, exclude_dates\n",
    "from helpers.match_helpers import get_matched_dataframes\n",
    "\n",
    "exclude_dates2 = copy.deepcopy(exclude_dates)\n",
    "exclude_dates2[\"/r/Incels\"].append([pd.to_datetime(\"2017-12-03\"), pd.to_datetime(\"2017-12-03\")] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads data + basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Authors</th>\n",
       "      <th>Submissions</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venue</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/r/Incels</th>\n",
       "      <td>18088</td>\n",
       "      <td>17403</td>\n",
       "      <td>340650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/The_Donald</th>\n",
       "      <td>80002</td>\n",
       "      <td>251090</td>\n",
       "      <td>2703615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incels.co</th>\n",
       "      <td>2270</td>\n",
       "      <td>25139</td>\n",
       "      <td>385765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thedonald.win</th>\n",
       "      <td>38510</td>\n",
       "      <td>280156</td>\n",
       "      <td>2390641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unique Authors  Submissions  Comments\n",
       "venue                                               \n",
       "/r/Incels               18088        17403    340650\n",
       "/r/The_Donald           80002       251090   2703615\n",
       "incels.co                2270        25139    385765\n",
       "thedonald.win           38510       280156   2390641"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"/data/manoel/platform_bans/data/\"\n",
    "df = pd.read_feather(DATA_PATH + \"processed_merged.f\")\n",
    "tdcons = ((df.venue == \"/r/The_Donald\") | (df.venue == \"thedonald.win\")) &\\\n",
    "        ((df.date_post >= interventions['/r/The_Donald'][\"Measure\"] - timedelta(days=120)) &\\\n",
    "        (df.date_post <= interventions['/r/The_Donald'][\"Measure\"] + timedelta(days=119)))\n",
    "\n",
    "incons = ((df.venue == \"/r/Incels\") | (df.venue == \"incels.co\")) &\\\n",
    "        ((df.date_post >= interventions['/r/Incels'][\"Measure\"] - timedelta(days=120)) &\\\n",
    "        (df.date_post <= interventions['/r/Incels'][\"Measure\"] + timedelta(days=119)))\n",
    "\n",
    "tostats = df.loc[incons | tdcons]\n",
    "tostatsgb = tostats.groupby(\"venue\")\\\n",
    "    .agg({\"author\": pd.Series.nunique,\n",
    "          'type': [lambda x: np.sum(x == \"submission\"), \n",
    "                   lambda x: np.sum(x == \"comment\")],\n",
    "          }).T.reset_index(drop=True).rename({0: \"Unique Authors\", 1: \"Submissions\", 2: \"Comments\"}).T\n",
    "del tostats\n",
    "tostatsgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Activity)\n",
    "\n",
    "df.loc[df[\"venue\"] == \"incels.co\", \"venue\"] = \"/r/Incels\"\n",
    "df.loc[df[\"venue\"] == \"thedonald.win\", \"venue\"] = \"/r/The_Donald\"\n",
    "\n",
    "# Gets mean values per day per venue\n",
    "df_activity = df.loc[(~df.body.isna())]\\\n",
    "                .groupby([\"venue\", pd.Grouper(key='date_post', freq='d')])\\\n",
    "                .agg({\"id\": len, \n",
    "                      \"author\": pd.Series.nunique,\n",
    "                      'length': np.nanmean\n",
    "                      }).reset_index()\n",
    "\n",
    "# Restricts data to 60 days before and after intervention\n",
    "df_activity = df_activity.loc[\n",
    "    get_slice_date_venue(df_activity, \"/r/The_Donald\", interventions[\"/r/The_Donald\"][\"Measure\"], 120, 119) |\n",
    "    get_slice_date_venue(df_activity, \"/r/Incels\", interventions[\"/r/Incels\"][\"Measure\"], 120, 119) \n",
    "]\n",
    "\n",
    "# Gets number of NEW authors per day\n",
    "df_first = df.groupby([\"author\", \"venue\"]).date_post.min().reset_index()\n",
    "df_first_grouped = df_first.groupby([\"venue\", pd.Grouper(key='date_post', freq='d')]).count()\n",
    "df_first_grouped = df_first_grouped.rename({\"author\": \"first\"}, axis=1)\n",
    "df_first_grouped.reset_index(inplace=True)\n",
    "df_all = df_activity.merge(df_first_grouped, \n",
    "                           left_on=[\"venue\", \"date_post\"], \n",
    "                           right_on=[\"venue\", \"date_post\"], \n",
    "                           how=\"inner\")\n",
    "\n",
    "# Gets micro fraction between number of comments and number of authors\n",
    "df_all[\"idpauthor\"] = df_all[\"id\"] / df_all[\"author\"]\n",
    "\n",
    "# sets intervention stuff\n",
    "df_all[\"intervention_flag\"] = 0\n",
    "set_intervention_stuff(df_all, \"/r/Incels\", interventions[\"/r/Incels\"][\"Measure\"])\n",
    "set_intervention_stuff(df_all, \"/r/The_Donald\", interventions[\"/r/The_Donald\"][\"Measure\"])\n",
    "df_all.date_idx = df_all.date_idx.apply(lambda x: x.days)\n",
    "\n",
    "# saves data\n",
    "df_all.to_csv(\"./data/reproducibility_data/activity_agg.csv\", index=False)\n",
    "\n",
    "# (Content)\n",
    "\n",
    "# Gets mean values per day per venue\n",
    "fixation_dict = ((df.fixation_dict_incels > 0) & (df.venue == \"/r/Incels\") |\n",
    "                (df.fixation_dict_td > 0) & (df.venue == \"/r/The_Donald\"))\n",
    "\n",
    "df_content = get_content_helper(df, days_before=120, days_after=119)\n",
    "df_norm = get_content_helper(df[fixation_dict], days_before=120, days_after=119)\n",
    "df_content.to_csv(\"./data/reproducibility_data/content_agg.csv\", index=False)\n",
    "df_norm.to_csv(\"./data/reproducibility_data/content_agg_fixation_dict.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepares user level dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quartiles before [  1.   7.  27. 101.]\n",
      "quartiles after [ 1  2  6 31]\n",
      "quartiles before [  1.  19. 116. 398.]\n",
      "quartiles after [ 1  2  9 64]\n",
      "quartiles before [ 1.  2.  7. 20.]\n",
      "quartiles after [1 1 3 9]\n",
      "quartiles before [  1.  12.  42. 149.]\n",
      "quartiles after [ 1  2  6 34]\n"
     ]
    }
   ],
   "source": [
    "# Prepares matched dataframes!\n",
    "df = pd.read_feather(DATA_PATH + \"processed_merged.f\")\n",
    "\n",
    "pairs_td, df_td_users_matched, df_gb_td, df_before_after_td = get_matched_dataframes(\n",
    "    df_ = df,\n",
    "    reddit_venue=\"/r/The_Donald\",\n",
    "    fringe_venue=\"thedonald.win\",\n",
    "    migration_date=interventions[\"/r/The_Donald\"][\"Measure\"],\n",
    "    grace_period=grace_period[\"/r/The_Donald\"],\n",
    "    days_before=120,\n",
    "    days_after=119\n",
    ")\n",
    "\n",
    "pairs_in, df_in_users_matched, df_gb_in, df_before_after_in = get_matched_dataframes(\n",
    "    df_ = df,\n",
    "    reddit_venue=\"/r/Incels\",\n",
    "    fringe_venue=\"incels.co\",\n",
    "    migration_date=interventions[\"/r/Incels\"][\"Measure\"],\n",
    "    grace_period=grace_period[\"/r/Incels\"],\n",
    "    days_before=120,\n",
    "    days_after=119\n",
    ")\n",
    "\n",
    "pairs_td_f, df_td_users_matched_f, df_gb_td_f, df_before_after_td_f = get_matched_dataframes(\n",
    "    df_ = df.loc[df[\"fixation_dict_td\"] > 0],\n",
    "    reddit_venue=\"/r/The_Donald\",\n",
    "    fringe_venue=\"thedonald.win\",\n",
    "    migration_date=interventions[\"/r/The_Donald\"][\"Measure\"],\n",
    "    grace_period=grace_period[\"/r/The_Donald\"],\n",
    "    days_before=120,\n",
    "    days_after=119\n",
    ")\n",
    "\n",
    "pairs_in_f, df_in_users_matched_f, df_gb_in_f, df_before_after_in_f = get_matched_dataframes(\n",
    "    df_ = df.loc[df[\"fixation_dict_incels\"] > 0],\n",
    "    reddit_venue=\"/r/Incels\",\n",
    "    fringe_venue=\"incels.co\",\n",
    "    migration_date=interventions[\"/r/Incels\"][\"Measure\"],\n",
    "    grace_period=grace_period[\"/r/Incels\"],\n",
    "    days_before=120,\n",
    "    days_after=119\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets mean values per day per venue\n",
    "xum = pd.concat([df_td_users_matched, df_in_users_matched])\n",
    "d = {\"incels.co\": \"/r/Incels\", \"thedonald.win\": \"/r/The_Donald\"}\n",
    "xum[\"venue\"] = xum.venue.apply(lambda x: d[x] if x in d else x)\n",
    "df_content = get_content_helper(xum, days_before=120, days_after=119)\n",
    "\n",
    "# Gets mean values per day per venue\n",
    "xum = pd.concat([df_td_users_matched, df_in_users_matched])\n",
    "d = {\"incels.co\": \"/r/Incels\", \"thedonald.win\": \"/r/The_Donald\"}\n",
    "xum[\"venue\"] = xum.venue.apply(lambda x: d[x] if x in d else x)\n",
    "fixation_dict = ((xum.fixation_dict_incels > 0) & (xum.venue == \"/r/Incels\") |\n",
    "                (xum.fixation_dict_td > 0) & (xum.venue == \"/r/The_Donald\"))\n",
    "df_norm = get_content_helper(xum[fixation_dict],  days_before=120, days_after=119)\n",
    "df_content.to_csv(\"./data/reproducibility_data/content_matched_agg.csv\", index=False)\n",
    "df_norm.to_csv(\"./data/reproducibility_data/content_matched_agg_fixation_dict.csv\", index=False)\n",
    "\n",
    "to_drop = ['SEVERE_TOXICITY_x', 'kind_x', 'SEVERE_TOXICITY_y', 'kind_y', 'ptile_after', 'group_after']\n",
    "df_before_after_td.drop(to_drop, axis=1)\\\n",
    "    .rename({\"before\":\"num_posts_x\", \"after\": \"num_posts_y\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_matched_td.csv\", index=False)\n",
    "df_before_after_in.drop(to_drop, axis=1)\\\n",
    "    .rename({\"before\":\"num_posts_x\", \"after\": \"num_posts_y\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_matched_incels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['SEVERE_TOXICITY_x', 'kind_x', 'SEVERE_TOXICITY_y', 'kind_y', 'ptile_after', 'group_after']\n",
    "df_before_after_td.drop(to_drop, axis=1)\\\n",
    "    .rename({\"before\":\"num_posts_x\", \"after\": \"num_posts_y\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_matched_td.csv\", index=False)\n",
    "df_before_after_in.drop(to_drop, axis=1)\\\n",
    "    .rename({\"before\":\"num_posts_x\", \"after\": \"num_posts_y\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_matched_incels.csv\", index=False)\n",
    "\n",
    "to_drop = ['author']\n",
    "df_gb_td.drop(to_drop, axis=1)\\\n",
    "    .rename({\"body\":\"num_posts\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_td.csv\", index=False)\n",
    "df_gb_in.drop(to_drop, axis=1)\\\n",
    "    .rename({\"body\":\"num_posts\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_incels.csv\", index=False)\n",
    "\n",
    "to_drop = ['SEVERE_TOXICITY_x', 'kind_x', 'SEVERE_TOXICITY_y', 'kind_y', 'ptile_after', 'group_after']\n",
    "df_before_after_td_f.drop(to_drop, axis=1)\\\n",
    "    .rename({\"before\":\"num_posts_x\", \"after\": \"num_posts_y\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_matched_td_f.csv\", index=False)\n",
    "df_before_after_in_f.drop(to_drop, axis=1)\\\n",
    "    .rename({\"before\":\"num_posts_x\", \"after\": \"num_posts_y\"}, axis=1)\\\n",
    "    .to_csv(\"./data/reproducibility_data/user_matched_incels_f.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manosphere",
   "language": "python",
   "name": "manosphere"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}